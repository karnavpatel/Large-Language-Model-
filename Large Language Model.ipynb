{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6de812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\16475\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\16475\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\16475\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\16475\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\16475\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\16475\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69eba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c336ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "Once upon a time, in a land far, far away, there lived a king and queen who had a beautiful daughter. The princess was kind and gentle, and everyone loved her.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf60780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\16475\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['once', 'upon', 'a', 'time', ',', 'in', 'a', 'land', 'far', ',', 'far', 'away', ',', 'there', 'lived', 'a', 'king', 'and', 'queen', 'who', 'had', 'a', 'beautiful', 'daughter', '.', 'the', 'princess', 'was', 'kind', 'and', 'gentle', ',', 'and', 'everyone', 'loved', 'her', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "tokens = nltk.word_tokenize(sample_text.lower())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d02d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'collections.Counter'>, {'once': Counter({'upon': 1}), 'upon': Counter({'a': 1}), 'a': Counter({'time': 1, 'land': 1, 'king': 1, 'beautiful': 1}), 'time': Counter({',': 1}), ',': Counter({'in': 1, 'far': 1, 'there': 1, 'and': 1}), 'in': Counter({'a': 1}), 'land': Counter({'far': 1}), 'far': Counter({',': 1, 'away': 1}), 'away': Counter({',': 1}), 'there': Counter({'lived': 1}), 'lived': Counter({'a': 1}), 'king': Counter({'and': 1}), 'and': Counter({'queen': 1, 'gentle': 1, 'everyone': 1}), 'queen': Counter({'who': 1}), 'who': Counter({'had': 1}), 'had': Counter({'a': 1}), 'beautiful': Counter({'daughter': 1}), 'daughter': Counter({'.': 1}), '.': Counter({'the': 1}), 'the': Counter({'princess': 1}), 'princess': Counter({'was': 1}), 'was': Counter({'kind': 1}), 'kind': Counter({'and': 1}), 'gentle': Counter({',': 1}), 'everyone': Counter({'loved': 1}), 'loved': Counter({'her': 1}), 'her': Counter({'.': 1})})\n"
     ]
    }
   ],
   "source": [
    "bigrams = list(ngrams(tokens, 2))\n",
    "bigram_freq = defaultdict(Counter)\n",
    "\n",
    "for w1, w2 in bigrams:\n",
    "    bigram_freq[w1][w2] += 1\n",
    "\n",
    "print(bigram_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eccd64f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "princess was kind and gentle ,\n"
     ]
    }
   ],
   "source": [
    "def generate_text(seed, n_words):\n",
    "    result = [seed]\n",
    "    for _ in range(n_words):\n",
    "        next_word_options = bigram_freq[result[-1]]\n",
    "        next_word = random.choices(list(next_word_options.keys()), list(next_word_options.values()))[0]\n",
    "        result.append(next_word)\n",
    "    return ' '.join(result)\n",
    "\n",
    "generated_text = generate_text('princess', 5)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dabe3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bfef68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_text = \"your_previous_text_data\"\n",
    "new_text = \"your_new_text_data\"\n",
    "combined_text = old_text + \" \" + new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a2957f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = sent_tokenize(combined_text)\n",
    "word_tokens = [word_tokenize(t) for t in sent_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744ea0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "363628fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLE(n)\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14401007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the importance\n",
      "Answer: <s> <s> your_previous_text_data your_new_text_data </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n",
      "Question: How does it work\n",
      "Answer: <s> your_previous_text_data your_new_text_data </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n",
      "Question: What are the benefits\n",
      "Answer: <s> your_previous_text_data your_new_text_data </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n",
      "Question: How can I improve\n",
      "Answer: <s> your_previous_text_data your_new_text_data </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n",
      "Question: What should I consider\n",
      "Answer: your_previous_text_data your_new_text_data </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, num_words, model):\n",
    "    word_list = model.generate(num_words, text_seed=prompt.split())\n",
    "    response = ' '.join(word_list)\n",
    "    return response\n",
    "\n",
    "# Example questions\n",
    "questions = [\n",
    "    \"What is the importance\",\n",
    "    \"How does it work\",\n",
    "    \"What are the benefits\",\n",
    "    \"How can I improve\",\n",
    "    \"What should I consider\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {generate_text(question, 20, model)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f1b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import bigrams, FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3db3239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text data\n",
    "text = \"Natural Language Processing (NLP) is a field of artificial intelligence and computational linguistics that focuses on the interaction between computers and human language. It involves the development of algorithms and models that enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful. NLP encompasses a wide range of tasks and techniques, including:Text Understanding: NLP algorithms analyze and extract meaning from text data. This includes tasks such as part-of-speech tagging, named entity recognition, syntactic parsing, and semantic role labeling.Sentiment Analysis: NLP algorithms can determine the sentiment or opinion expressed in a piece of text. They can identify whether a statement is positive, negative, or neutral, which is useful for analyzing customer feedback, social media sentiment, and reviews.Machine Translation: NLP enables the automatic translation of text from one language to another. Machine translation systems use statistical or neural network-based models to understand the meaning of the source language and generate an equivalent translation in the target language.Information Retrieval: NLP techniques are employed to retrieve relevant information from a large corpus of text. Search engines, for example, use NLP algorithms to understand user queries and retrieve relevant documents or web pages.Text Generation: NLP models can generate human-like text. This includes applications such as chatbots, language translation, and text summarization.Question Answering: NLP systems can understand questions posed in natural language and provide relevant answers. Question answering systems are used in chatbots, virtual assistants, and information retrieval systems.NLP algorithms rely on a combination of machine learning, statistical analysis, linguistic rules, and semantic understanding to process and interpret human language. They often leverage large annotated datasets to learn patterns and relationships between words and phrases, enabling them to make accurate predictions and understand the meaning behind the text.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e355fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bigrams and their frequency distribution\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "bigram_freq_dist = FreqDist(bigrams)\n",
    "\n",
    "# Prepare the dataset for training\n",
    "train_data, padded_sents = padded_everygram_pipeline(2, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c1cb35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the bigram model\n",
    "model = MLE(2)\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59f4fd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is natural language processing?\n",
      "A: language s . </s> </s> a l d </s> </s>\n",
      "\n",
      "Q: How does artificial intelligence relate to linguistics?\n",
      "A: How e r i o r g i n s\n",
      "\n",
      "Q: Can computers understand human language?\n",
      "A: ? . </s> g n g o n f </s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(model, num_words, seed_word):\n",
    "    sentence = [seed_word]\n",
    "    for _ in range(num_words - 1):\n",
    "        next_word = model.generate(1, text_seed=sentence)\n",
    "        sentence.append(next_word)\n",
    "\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Example questions to the model\n",
    "questions = [\n",
    "    \"What is natural language processing?\",\n",
    "    \"How does artificial intelligence relate to linguistics?\",\n",
    "    \"Can computers understand human language?\",\n",
    "]\n",
    "\n",
    "# Generate answers for the questions\n",
    "for question in questions:\n",
    "    tokens = nltk.word_tokenize(question)\n",
    "    seed_word = choice(tokens)\n",
    "    generated_sentence = generate_sentence(model, 10, seed_word)\n",
    "    print(f\"Q: {question}\\nA: {generated_sentence}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1062c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
